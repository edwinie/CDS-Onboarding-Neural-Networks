{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. How does an SVR work? \n",
    "Support Vector Regression predicts continuous outcomes by fitting a hyperplane within an acceptable margin, penalizing errors only beyond that boundary. It uses kernel functions to transform data into higher dimensions, enabling it to capture nonlinear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. How is this similar to or different from linear regression? What do \n",
    "the different kernel types between linear, polynomial, and radial \n",
    "basis function (RBF) do? \n",
    "SVR resembles linear regression by predicting continuous values but differs by penalizing only errors exceeding a certain margin, rather than all deviations. Kernels distinguish SVR from linear regression: linear kernels model straightforward linear trends, polynomial kernels capture complex interactions, and radial basis function kernels handle intricate nonlinear patterns through similarity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. For each kernel, what happens when you increase or decrease the \n",
    "magnitudes of hyperparameters C and gamma? Why? Justify with \n",
    "plots. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
