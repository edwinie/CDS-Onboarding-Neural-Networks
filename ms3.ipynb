{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ywpok\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ywpok\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ywpok\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ywpok\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ywpok\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1209867\n",
      "Validation set size: 259257\n",
      "Test set size: 259258\n"
     ]
    }
   ],
   "source": [
    "# 1 part a\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, target_column, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, and test sets.\n",
    "    \"\"\"\n",
    "    assert train_size + val_size + test_size == 1, \"Splits must sum to 1\"\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Split into training and temp set (for validation and test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - train_size), random_state=random_state)\n",
    "    \n",
    "    # Split temp set into validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_size/(test_size + val_size), random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./Top_spotify_songs.csv\")\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df, target_column=\"popularity\")\n",
    "\n",
    "print(\"Train set size: \"+ str(len(X_train)))\n",
    "print(\"Validation set size: \" + str(len(X_val)))\n",
    "print(\"Test set size: \"+ str(len(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1209867, 24), y_train shape: (1209867,)\n",
      "X_val shape: (259257, 24), y_val shape: (259257,)\n",
      "X_test shape:(259258, 24), y_test shape: (259258,)\n"
     ]
    }
   ],
   "source": [
    "# part 1 b\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df, target_column=\"popularity\")\n",
    "\n",
    "# Print the shapes of the splits\n",
    "print(\"X_train shape: \" + str(X_train.shape)+\", y_train shape: \" + str(y_train.shape))\n",
    "print(f\"X_val shape: \"+str(X_val.shape) + \", y_val shape: \" + str(y_val.shape))\n",
    "print(f\"X_test shape:\"+str(X_test.shape) + \", y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Create and save correlation matrix\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m create_correlation_matrix(\u001b[43mdf_encoded\u001b[49m, target_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopularity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "#part 1 c\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_correlation_matrix(df, target_column):\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df_numeric = df[numeric_cols]\n",
    "    \"\"\"\n",
    "    Creates and saves a correlation matrix between features and the target column.\n",
    "    \"\"\"\n",
    "    correlation_matrix = df_numeric.corr()\n",
    "\n",
    "    corr_with_target = correlation_matrix[target_column].abs().sort_values(ascending=False)\n",
    "    top_features = corr_with_target.head(15).index  \n",
    "    \n",
    "    reduced_corr_matrix = correlation_matrix.loc[top_features, top_features]\n",
    "\n",
    "    # Set up the plot size and style\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(reduced_corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "\n",
    "    plt.title(f\"Correlation Matrix for {target_column}\")\n",
    "    plt.savefig(f\"correlation_matrix_{target_column}.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Create and save correlation matrix\n",
    "create_correlation_matrix(df_encoded, target_column=\"popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scatterplots saved.\n"
     ]
    }
   ],
   "source": [
    "# 1 part d\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only numeric columns\n",
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df_numeric.corr()\n",
    "\n",
    "# Unstack and sort correlation values\n",
    "corr_matrix_unstacked = corr_matrix.abs().unstack()\n",
    "sorted_corr = corr_matrix_unstacked.sort_values(ascending=False)\n",
    "\n",
    "# Filter out self-correlations (the diagonal)\n",
    "sorted_corr = sorted_corr[sorted_corr < 1]\n",
    "\n",
    "# Get the top N highly correlated feature pairs (you can change the number as needed)\n",
    "top_n = 5\n",
    "top_corr_pairs = sorted_corr.head(top_n)\n",
    "\n",
    "# Create scatterplots for each pair with the highest correlation\n",
    "for (feature1, feature2), corr_value in top_corr_pairs.items():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=df[feature1], y=df[feature2])\n",
    "    plt.title(f\"Scatter plot between {feature1} and {feature2} (Correlation: {corr_value:.2f})\")\n",
    "    plt.xlabel(feature1)\n",
    "    plt.ylabel(feature2)\n",
    "    plt.savefig(f\"scatterplot_{feature1}_{feature2}.png\")  # Save the plot as PNG\n",
    "    plt.close()  # Close the plot to avoid memory issues\n",
    "\n",
    "print(\"Scatterplots saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (Features: ['danceability', 'energy', 'duration_ms'])\n",
      "Mean Squared Error: 247.91, R² Score: 0.00\n",
      "\n",
      "Model 2 (Features: ['key', 'loudness', 'speechiness'])\n",
      "Mean Squared Error: 241.24, R² Score: 0.03\n",
      "\n",
      "Model 3 (Features: ['acousticness', 'instrumentalness', 'tempo'])\n",
      "Mean Squared Error: 246.84, R² Score: 0.01\n"
     ]
    }
   ],
   "source": [
    "#1 part e\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Select target column\n",
    "target_column = 'popularity'\n",
    "\n",
    "# 1. Select Features for Model 1: Based on high correlation with target\n",
    "features_model_1 = ['danceability', 'energy', 'duration_ms']\n",
    "\n",
    "# 2. Select Features for Model 2: Based on high correlation among features\n",
    "features_model_2 = ['key', 'loudness', 'speechiness']\n",
    "\n",
    "# 3. Select Features for Model 3: Random selection of features\n",
    "features_model_3 = ['acousticness', 'instrumentalness', 'tempo']\n",
    "\n",
    "def train_model(features):\n",
    "    # Split data into X (features) and y (target)\n",
    "    X = df[features]\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Split data into train and test sets (70% train, 30% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Initialize the linear regression model\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "# Train and evaluate 3 models with different feature sets\n",
    "model_1, mse_1, r2_1 = train_model(features_model_1)\n",
    "model_2, mse_2, r2_2 = train_model(features_model_2)\n",
    "model_3, mse_3, r2_3 = train_model(features_model_3)\n",
    "\n",
    "print(f\"Model 1 (Features: {features_model_1})\")\n",
    "print(f\"Mean Squared Error: {mse_1:.2f}, R² Score: {r2_1:.2f}\")\n",
    "\n",
    "print(f\"\\nModel 2 (Features: {features_model_2})\")\n",
    "print(f\"Mean Squared Error: {mse_2:.2f}, R² Score: {r2_2:.2f}\")\n",
    "\n",
    "print(f\"\\nModel 3 (Features: {features_model_3})\")\n",
    "print(f\"Mean Squared Error: {mse_3:.2f}, R² Score: {r2_3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- acousticness\n- album_name\n- album_release_date\n- artists\n- country\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m model_3, mse_train_3, r2_train_3 = train_model(features_model_3)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Generate predictions on the training set for plotting\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m y_train_pred_1 = \u001b[43mmodel_1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m y_train_pred_2 = model_2.predict(X_train)\n\u001b[32m     20\u001b[39m y_train_pred_3 = model_3.predict(X_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_base.py:297\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    284\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    286\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_base.py:276\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    274\u001b[39m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     coef_ = \u001b[38;5;28mself\u001b[39m.coef_\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coef_.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2836\u001b[39m     _estimator,\n\u001b[32m   2837\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2843\u001b[39m     **check_params,\n\u001b[32m   2844\u001b[39m ):\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2846\u001b[39m \n\u001b[32m   2847\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2918\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2777\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2775\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- acousticness\n- album_name\n- album_release_date\n- artists\n- country\n- ...\n"
     ]
    }
   ],
   "source": [
    "# 1 part f\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'popularity' \n",
    "features_model_1 = ['danceability', 'energy']\n",
    "features_model_2 = ['danceability', 'energy', 'loudness']\n",
    "features_model_3 = ['danceability', 'energy', 'speechiness']\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df, target_column)\n",
    "\n",
    "# Train models and get the training MSE and R²\n",
    "model_1, mse_train_1, r2_train_1 = train_model(features_model_1)\n",
    "model_2, mse_train_2, r2_train_2 = train_model(features_model_2)\n",
    "model_3, mse_train_3, r2_train_3 = train_model(features_model_3)\n",
    "\n",
    "# Generate predictions on the training set for plotting\n",
    "y_train_pred_1 = model_1.predict(X_train)\n",
    "y_train_pred_2 = model_2.predict(X_train)\n",
    "y_train_pred_3 = model_3.predict(X_train)\n",
    "\n",
    "# Plot the training data for each model\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_train, y_train_pred_1, alpha=0.5)  # Use y_train_pred_1 instead of model_1.predict(X_train)\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--')\n",
    "plt.title(f'Model 1: Training Data - {model_1.__class__.__name__}')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.savefig(\"model_1_training_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_train, y_train_pred_2, alpha=0.5)  # Use y_train_pred_2 instead of model_2.predict(X_train)\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--')\n",
    "plt.title(f'Model 2: Training Data - {model_2.__class__.__name__}')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.savefig(\"model_2_training_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_train, y_train_pred_3, alpha=0.5)  # Use y_train_pred_3 instead of model_3.predict(X_train)\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--')\n",
    "plt.title(f'Model 3: Training Data - {model_3.__class__.__name__}')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.savefig(\"model_3_training_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Create a table of training errors\n",
    "error_table = pd.DataFrame({\n",
    "    'Model': ['Model 1', 'Model 2', 'Model 3'],\n",
    "    'Training Error (MSE)': [mse_train_1, mse_train_2, mse_train_3],\n",
    "    'Training R2': [r2_train_1, r2_train_2, r2_train_3]\n",
    "})\n",
    "\n",
    "print(error_table)\n",
    "\n",
    "# Model 1 performance on validation set\n",
    "y_val_pred_1 = model_1.predict(X_val)\n",
    "mse_val_1 = mean_squared_error(y_val, y_val_pred_1)\n",
    "r2_val_1 = r2_score(y_val, y_val_pred_1)\n",
    "\n",
    "# Model 2 performance on validation set\n",
    "y_val_pred_2 = model_2.predict(X_val)\n",
    "mse_val_2 = mean_squared_error(y_val, y_val_pred_2)\n",
    "r2_val_2 = r2_score(y_val, y_val_pred_2)\n",
    "\n",
    "# Model 3 performance on validation set\n",
    "y_val_pred_3 = model_3.predict(X_val)\n",
    "mse_val_3 = mean_squared_error(y_val, y_val_pred_3)\n",
    "r2_val_3 = r2_score(y_val, y_val_pred_3)\n",
    "\n",
    "# Add validation errors to the table\n",
    "error_table['Validation Error (MSE)'] = [mse_val_1, mse_val_2, mse_val_3]\n",
    "error_table['Validation R2'] = [r2_val_1, r2_val_2, r2_val_3]\n",
    "\n",
    "print(error_table)\n",
    "\n",
    "# Find the model with the lowest validation error\n",
    "best_model_index = error_table['Validation Error (MSE)'].idxmin()\n",
    "best_model = error_table.iloc[best_model_index]\n",
    "\n",
    "print(f\"Best model based on validation MSE: {best_model['Model']}\")\n",
    "\n",
    "# Evaluate the best model on the test set and report the test error\n",
    "if best_model['Model'] == 'Model 1':\n",
    "    y_test_pred = model_1.predict(X_test)\n",
    "elif best_model['Model'] == 'Model 2':\n",
    "    y_test_pred = model_2.predict(X_test)\n",
    "else:\n",
    "    y_test_pred = model_3.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Error (MSE) for {best_model['Model']}: {mse_test}\")\n",
    "print(f\"Test R2 for {best_model['Model']}: {r2_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
