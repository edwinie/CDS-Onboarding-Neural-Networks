{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1209867\n",
      "Validation set size: 259257\n",
      "Test set size: 259258\n"
     ]
    }
   ],
   "source": [
    "# 1 part a\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, target_column, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, and test sets.\n",
    "    \"\"\"\n",
    "    assert train_size + val_size + test_size == 1, \"Splits must sum to 1\"\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Split into training and temp set (for validation and test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - train_size), random_state=random_state)\n",
    "    \n",
    "    # Split temp set into validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_size/(test_size + val_size), random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./Top_spotify_songs.csv\")\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df, target_column=\"popularity\")\n",
    "\n",
    "print(\"Train set size: \"+ str(len(X_train)))\n",
    "print(\"Validation set size: \" + str(len(X_val)))\n",
    "print(\"Test set size: \"+ str(len(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1209867, 24), y_train shape: (1209867,)\n",
      "X_val shape: (259257, 24), y_val shape: (259257,)\n",
      "X_test shape:(259258, 24), y_test shape: (259258,)\n"
     ]
    }
   ],
   "source": [
    "# part 1 b\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df, target_column=\"popularity\")\n",
    "\n",
    "# Print the shapes of the splits\n",
    "print(\"X_train shape: \" + str(X_train.shape)+\", y_train shape: \" + str(y_train.shape))\n",
    "print(f\"X_val shape: \"+str(X_val.shape) + \", y_val shape: \" + str(y_val.shape))\n",
    "print(f\"X_test shape:\"+str(X_test.shape) + \", y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     plt.close()\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# One-hot encode categorical features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m df_encoded = encode_categorical_features(\u001b[43mdf\u001b[49m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Create and save correlation matrix\u001b[39;00m\n\u001b[32m     31\u001b[39m create_correlation_matrix(df_encoded, target_column=\u001b[33m\"\u001b[39m\u001b[33mpopularity\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#part 1 c\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def encode_categorical_features(df):\n",
    "    \"\"\"\n",
    "    Encodes categorical columns with one-hot encoding.\n",
    "    \"\"\"\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    return pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "def create_correlation_matrix(df, target_column):\n",
    "    \"\"\"\n",
    "    Creates and saves a correlation matrix between features and the target column.\n",
    "    \"\"\"\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    # Set up the plot size and style\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "\n",
    "    plt.title(f\"Correlation Matrix for {target_column}\")\n",
    "    plt.savefig(f\"correlation_matrix_{target_column}.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df_encoded = encode_categorical_features(df)\n",
    "\n",
    "# Create and save correlation matrix\n",
    "create_correlation_matrix(df_encoded, target_column=\"popularity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
